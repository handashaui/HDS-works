{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01cd435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/hanz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hanz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/hanz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/hanz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e5a5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = {\n",
    "\t\"intents\": [\n",
    "\t\t{\n",
    "\t\t\t\"tag\": \"greeting\",\n",
    "\t\t\t\"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\", \"Whats up\", \"Hey\", \"greetings\"],\n",
    "\t\t\t\"responses\": [\"Hello!\", \"Good to see you again!\", \"Hi there, how can I help?\"]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"tag\": \"goodbye\",\n",
    "\t\t\t\"patterns\": [\"cya\", \"See you later\", \"Goodbye\", \"I am Leaving\", \"Have a Good day\", \"bye\", \"cao\", \"see ya\"],\n",
    "\t\t\t\"responses\": [\"Sad to see you go :(\", \"Talk to you later\", \"Goodbye!\"]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"tag\": \"programming\",\n",
    "\t\t\t\"patterns\": [\"What is progamming?\", \"What is coding?\", \"Tell me about programming\", \"Tell me about coding\", \"What is software development?\"],\n",
    "\t\t\t\"responses\": [\"Programming, coding or software development, means writing computer code to automate tasks.\"]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"tag\": \"resource\",\n",
    "\t\t\t\"patterns\": [\"Where can I learn to code?\", \"Best way to learn to code\", \"How can I learn programming\", \"Good programming resources\",\n",
    "\t\t\t\t\t\t\t\t   \"Can you recommend good coding resources?\"],\n",
    "\t\t\t\"responses\": [\"Check out the NeuralNine YouTube channel and The Python Bible series (7 in 1).\"]\n",
    "\t\t},\n",
    "        {\n",
    "\t\t\t\"tag\": \"handsome\",\n",
    "\t\t\t\"patterns\": [\"who is the most handsome person\", \"the most handsome people in world\", \"handsome and cool\", \"who is more handsome than me\", \"Goodlooking man\"],\n",
    "\t\t\t\"responses\": [\"Handashuai!\", \"hanz is the most handsome people\", \"It must be handashuai\"]\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"tag\": \"stocks\",\n",
    "\t\t\t\"patterns\": [\"What are my stocks?\", \"Which stocks do I own?\", \"Show my stock portfolio\"],\n",
    "\t\t\t\"responses\": [\"Here are your stocks!\"]\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "\n",
    "with open(\"intents.json\", \"w\") as f:\n",
    "    json.dump(intents, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3ded9",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0148b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ChatbotModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dab6a5",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e4923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotAssistant:\n",
    "    \n",
    "    def __init__(self, intents_path, function_mappings = None):\n",
    "        self.model = None\n",
    "        self.intents_path = intents_path\n",
    "        \n",
    "        self.documents = []\n",
    "        self.vocabulary = []\n",
    "        self.intents = []\n",
    "        self.intents_responses = {}\n",
    "        \n",
    "        self.function_mappings = function_mappings\n",
    "        \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "    @staticmethod\n",
    "    def tokenize_and_lemmatize(text):\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        \n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "        \n",
    "        return words\n",
    "    \n",
    "    def bag_of_words(self, words):\n",
    "        return [1 if word in words else 0 for word in self.vocabulary]\n",
    "    \n",
    "    def parse_intents(self):\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        \n",
    "        if os.path.exists(self.intents_path):\n",
    "            with open(self.intents_path, 'r') as f:\n",
    "                intents_data = json.load(f)\n",
    "            \n",
    "            for intent in intents_data['intents']:\n",
    "                if intent['tag'] not in self.intents:\n",
    "                    self.intents.append(intent['tag'])\n",
    "                    self.intents_responses[intent['tag']] = intent['responses']\n",
    "                    \n",
    "                for pattern in intent['patterns']:\n",
    "                    pattern_words = self.tokenize_and_lemmatize(pattern)\n",
    "                    self.vocabulary.extend(pattern_words)\n",
    "                    self.documents.append((pattern_words, intent['tag']))\n",
    "                \n",
    "            self.vocabulary = sorted(set(self.vocabulary))\n",
    "            \n",
    "    def prepare_data(self):\n",
    "        bags = []\n",
    "        indices = []\n",
    "        \n",
    "        for document in self.documents:\n",
    "            words = document[0]\n",
    "            bag = self.bag_of_words(words)\n",
    "            \n",
    "            intent_index = self.intents.index(document[1])\n",
    "            \n",
    "            bags.append(bag)\n",
    "            indices.append(intent_index)\n",
    "            \n",
    "        self.X = np.array(bags)\n",
    "        self.y = np.array(indices)\n",
    "        \n",
    "    def train_model(self, batch_size, lr, epochs):\n",
    "        X_tensor = torch.tensor(self.X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.model = ChatbotModel(self.X.shape[1], len(self.intents))\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for batch_X, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch: {epoch+1} Loss: {running_loss/ len(loader):.4f} \")\n",
    "\n",
    "    def save_model(self, model_path, dimensions_path):\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "        with open(dimensions_path, 'w') as f:\n",
    "            json.dump({ 'input_size': self.X.shape[1], 'output_size': len(self.intents)}, f)\n",
    "\n",
    "    def load_model(self, model_path, dimensions_path):\n",
    "        with open(dimensions_path, 'r') as f:\n",
    "            dimensions = json.load(f)\n",
    "\n",
    "            self.model = ChatbotModel(dimensions['input_size'], dimensions['output_size'])\n",
    "            self.model.load_state_dict(torch.load(model_path, weight_only=True))\n",
    "\n",
    "    def process_message(self, input_message):\n",
    "        words = self.tokenize_and_lemmatize(input_message)\n",
    "        bag = self.bag_of_words(words)\n",
    "\n",
    "        bag_tensor = torch.tensor([bag], dtype=torch.float32)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(bag_tensor)\n",
    "\n",
    "        predicted_class_index = torch.argmax(predictions, dim=1).item()\n",
    "        predicted_intent = self.intents[predicted_class_index]\n",
    "\n",
    "        if self.function_mappings:\n",
    "            if predicted_intent in self.function_mappings:\n",
    "                self.function_mappings[predicted_intent]()\n",
    "\n",
    "        if self.intents_responses[predicted_intent]:\n",
    "            return random.choice(self.intents_responses[predicted_intent])\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74c4d38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hanz/anaconda3'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45af0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.7861 \n",
      "Epoch: 2 Loss: 1.7939 \n",
      "Epoch: 3 Loss: 1.7961 \n",
      "Epoch: 4 Loss: 1.7801 \n",
      "Epoch: 5 Loss: 1.7614 \n",
      "Epoch: 6 Loss: 1.7215 \n",
      "Epoch: 7 Loss: 1.7376 \n",
      "Epoch: 8 Loss: 1.7435 \n",
      "Epoch: 9 Loss: 1.6925 \n",
      "Epoch: 10 Loss: 1.6977 \n",
      "Epoch: 11 Loss: 1.6836 \n",
      "Epoch: 12 Loss: 1.6808 \n",
      "Epoch: 13 Loss: 1.6557 \n",
      "Epoch: 14 Loss: 1.6464 \n",
      "Epoch: 15 Loss: 1.6391 \n",
      "Epoch: 16 Loss: 1.6072 \n",
      "Epoch: 17 Loss: 1.5508 \n",
      "Epoch: 18 Loss: 1.5473 \n",
      "Epoch: 19 Loss: 1.5220 \n",
      "Epoch: 20 Loss: 1.3794 \n",
      "Epoch: 21 Loss: 1.4181 \n",
      "Epoch: 22 Loss: 1.4101 \n",
      "Epoch: 23 Loss: 1.2829 \n",
      "Epoch: 24 Loss: 1.3654 \n",
      "Epoch: 25 Loss: 1.1697 \n",
      "Epoch: 26 Loss: 1.3280 \n",
      "Epoch: 27 Loss: 1.2048 \n",
      "Epoch: 28 Loss: 1.1039 \n",
      "Epoch: 29 Loss: 1.0010 \n",
      "Epoch: 30 Loss: 0.9308 \n",
      "Epoch: 31 Loss: 0.9140 \n",
      "Epoch: 32 Loss: 0.9313 \n",
      "Epoch: 33 Loss: 0.8852 \n",
      "Epoch: 34 Loss: 0.7027 \n",
      "Epoch: 35 Loss: 0.6267 \n",
      "Epoch: 36 Loss: 0.6523 \n",
      "Epoch: 37 Loss: 0.6316 \n",
      "Epoch: 38 Loss: 0.5789 \n",
      "Epoch: 39 Loss: 0.6577 \n",
      "Epoch: 40 Loss: 0.4632 \n",
      "Epoch: 41 Loss: 0.4934 \n",
      "Epoch: 42 Loss: 0.4665 \n",
      "Epoch: 43 Loss: 0.4370 \n",
      "Epoch: 44 Loss: 0.4521 \n",
      "Epoch: 45 Loss: 0.2942 \n",
      "Epoch: 46 Loss: 0.3442 \n",
      "Epoch: 47 Loss: 0.3939 \n",
      "Epoch: 48 Loss: 0.3344 \n",
      "Epoch: 49 Loss: 0.2288 \n",
      "Epoch: 50 Loss: 0.3372 \n",
      "Epoch: 51 Loss: 0.2751 \n",
      "Epoch: 52 Loss: 0.2629 \n",
      "Epoch: 53 Loss: 0.1853 \n",
      "Epoch: 54 Loss: 0.2460 \n",
      "Epoch: 55 Loss: 0.1831 \n",
      "Epoch: 56 Loss: 0.2080 \n",
      "Epoch: 57 Loss: 0.2275 \n",
      "Epoch: 58 Loss: 0.1767 \n",
      "Epoch: 59 Loss: 0.1202 \n",
      "Epoch: 60 Loss: 0.1415 \n",
      "Epoch: 61 Loss: 0.1119 \n",
      "Epoch: 62 Loss: 0.1674 \n",
      "Epoch: 63 Loss: 0.1498 \n",
      "Epoch: 64 Loss: 0.1851 \n",
      "Epoch: 65 Loss: 0.1232 \n",
      "Epoch: 66 Loss: 0.1657 \n",
      "Epoch: 67 Loss: 0.0737 \n",
      "Epoch: 68 Loss: 0.1013 \n",
      "Epoch: 69 Loss: 0.1254 \n",
      "Epoch: 70 Loss: 0.1028 \n",
      "Epoch: 71 Loss: 0.1238 \n",
      "Epoch: 72 Loss: 0.0808 \n",
      "Epoch: 73 Loss: 0.1254 \n",
      "Epoch: 74 Loss: 0.0810 \n",
      "Epoch: 75 Loss: 0.1082 \n",
      "Epoch: 76 Loss: 0.1044 \n",
      "Epoch: 77 Loss: 0.1122 \n",
      "Epoch: 78 Loss: 0.1487 \n",
      "Epoch: 79 Loss: 0.0754 \n",
      "Epoch: 80 Loss: 0.0506 \n",
      "Epoch: 81 Loss: 0.0549 \n",
      "Epoch: 82 Loss: 0.0465 \n",
      "Epoch: 83 Loss: 0.0277 \n",
      "Epoch: 84 Loss: 0.0500 \n",
      "Epoch: 85 Loss: 0.1385 \n",
      "Epoch: 86 Loss: 0.0407 \n",
      "Epoch: 87 Loss: 0.0537 \n",
      "Epoch: 88 Loss: 0.0709 \n",
      "Epoch: 89 Loss: 0.1301 \n",
      "Epoch: 90 Loss: 0.0682 \n",
      "Epoch: 91 Loss: 0.0517 \n",
      "Epoch: 92 Loss: 0.0951 \n",
      "Epoch: 93 Loss: 0.0445 \n",
      "Epoch: 94 Loss: 0.0505 \n",
      "Epoch: 95 Loss: 0.0463 \n",
      "Epoch: 96 Loss: 0.0408 \n",
      "Epoch: 97 Loss: 0.0839 \n",
      "Epoch: 98 Loss: 0.0395 \n",
      "Epoch: 99 Loss: 0.0614 \n",
      "Epoch: 100 Loss: 0.0586 \n"
     ]
    }
   ],
   "source": [
    "def get_stock():\n",
    "    stocks = ['APPL', 'META', 'GS', 'MSTF']\n",
    "    \n",
    "    print(random.sample(stocks, 3))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    assistant = ChatbotAssistant('intents.json', function_mappings = {'stocks': get_stock})\n",
    "    assistant.parse_intents()\n",
    "    assistant.prepare_data()\n",
    "    assistant.train_model(batch_size=8, lr=0.001, epochs=100)\n",
    "    \n",
    "    assistant.save_model('chatbot_model.pth', 'dimensions.json')\n",
    "    \n",
    "    # assistant = ChatbotAssistant('intents.json', function_mappings = {'stocks': get_stock})\n",
    "    # assistant.parse_intents()\n",
    "    # assistant_save_model('chatbot_model.pth', 'dimensions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832dbb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your message: hi\n",
      "Hello!\n",
      "Enter your message: show me my stocks\n",
      "['META', 'APPL', 'GS']\n",
      "Here are your stocks!\n",
      "Enter your message: who is the most handsome people in the world\n",
      "hanz is the most handsome people\n",
      "Enter your message: thank you\n",
      "Hi there, how can I help?\n",
      "Enter your message: introduce me programming\n",
      "Programming, coding or software development, means writing computer code to automate tasks.\n",
      "Enter your message: bye\n",
      "Talk to you later\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input('Enter your message: ')\n",
    "    if message == 'quit':\n",
    "        break\n",
    "        \n",
    "    print(assistant.process_message(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bda96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
